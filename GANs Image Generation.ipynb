{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2dfee73",
   "metadata": {},
   "source": [
    "# GANs Image Generation\n",
    "\n",
    "In this notebook, we will explore how Generative Adversarial Networks (GANs) generate images. We will use a pretrained GAN model (BigGAN) to generate images from random noise.\n",
    "\n",
    "## Instructions\n",
    "1. Run the code below to generate an image from random noise.\n",
    "2. Modify the latent vector to generate different images.\n",
    "3. Experiment with generating different images by altering the latent vector and visualizing the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1448e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_biggan import (\n",
    "    BigGAN,\n",
    "    truncated_noise_sample,\n",
    "    save_as_images,\n",
    "    display_in_terminal\n",
    ")\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "#Load pre-trained BigGAN model\n",
    "model = BigGAN.from_pretrained('biggan-deep-256')\n",
    "model.eval()\n",
    "\n",
    "#Set truncation and batch size\n",
    "truncation = 0.4\n",
    "batch_size = 1\n",
    "\n",
    "#Generate random noise\n",
    "noise_vector = truncated_noise_sample(truncation=truncation, batch_size=batch_size)\n",
    "noise_vector = torch.from_numpy(noise_vector)\n",
    "\n",
    "#Create one-hot vector for class index (207 = golden retriever)\n",
    "class_vector = torch.zeros(batch_size, 1000)\n",
    "class_vector[0, 207] = 1  \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.to('cuda')\n",
    "    noise_vector = noise_vector.to('cuda')\n",
    "    class_vector = class_vector.to('cuda')\n",
    "\n",
    "#Generate image\n",
    "with torch.no_grad():\n",
    "    output = model(noise_vector, class_vector, truncation)\n",
    "\n",
    "#Move result to CPU\n",
    "output = output.to('cpu')\n",
    "\n",
    "# Display and save\n",
    "save_as_images(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0053511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/maggiekuo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Experiment with different latent vectors\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from pytorch_pretrained_biggan import BigGAN, one_hot_from_names, truncated_noise_sample\n",
    "import random\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "#Load model\n",
    "model = BigGAN.from_pretrained('biggan-deep-256')\n",
    "\n",
    "categories = ['soap bubble', 'coffee', 'mushroom', 'volcano', 'banana']\n",
    "\n",
    "#Experiment with different latent vectors\n",
    "latent_vector = truncated_noise_sample(truncation=0.1, batch_size=1)\n",
    "class_vector = one_hot_from_names([random.choice(categories)])\n",
    "truncation = 0.1\n",
    "\n",
    "#Convert to tensors\n",
    "noise_vector = torch.from_numpy(latent_vector).to('cpu')\n",
    "class_vector = torch.from_numpy(class_vector).to('cpu')\n",
    "\n",
    "#Generate image\n",
    "with torch.no_grad():\n",
    "    output = model(noise_vector, class_vector, truncation)\n",
    "\n",
    "#Convert to displayable image\n",
    "output = output.to('cpu')\n",
    "image_tensor = output.squeeze().numpy()\n",
    "image_tensor = (image_tensor * 255).astype('uint8')\n",
    "Image.fromarray(image_tensor.transpose(1, 2, 0)).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff7b1ff",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "\n",
    "Now that you have generated images, write a brief report reflecting on your observations:\n",
    "\n",
    "1. How did the generated images change when you modified the latent vector?\n",
    "2. What patterns did you notice in the generated images? Were they realistic?\n",
    "3. How does the process of generating images from noise differ from traditional image generation methods?\n",
    "4. What challenges or limitations did you observe with the GAN model?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
