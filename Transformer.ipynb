{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c7d2897",
   "metadata": {},
   "source": [
    "# Transformer Text Generation\n",
    "\n",
    "In this notebook, we will explore how transformer models (like GPT-2) can generate text based on a given prompt. We will experiment with generating text by adjusting parameters like temperature and sequence length.\n",
    "\n",
    "## Instructions\n",
    "1. Change the prompt below to experiment with different types of text generation.\n",
    "2. Adjust the `max_length` and `temperature` parameters to see how they affect the output.\n",
    "3. Generate at least 3 samples with different prompts and compare the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dbce095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maggiekuo/Documents/Cognizant Externship/Gen AI/ml_env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use mps:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the future, education will be a core issue for the federal government.\n",
      "\n",
      "\"It's not just about education. If we are going to be a smart country we need to be a smart government. If you look at the history of the United States, you're going to find it's a very poor country,\" said Eric Holder, Justice Department lawyer, during a press conference at the Justice Department.\n",
      "\n",
      "Holder said, \"If you look at our history, we've been on a trajectory of prosperity. We've been able to build a great society. We've been able to grow our economy and our economy has grown exponentially.\"\n",
      "\n",
      "The president's remarks were in response to a series of recent announcements from the Obama administration.\n",
      "\n",
      "The U.S. was also facing a potential civil rights crisis following the fatal shooting of a black man by two white police officers in January.\n",
      "\n",
      "The police killings followed a series of racially-motivated killings of black men by white officers in the early 1990s. Those killings led to the firing of more than 1,000 police officers.\n",
      "\n",
      "In April, President Obama announced that he was pulling the United States out of the Trans-Pacific Partnership, which includes 28 nations. The agreement is designed to bring the U.S. into\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load GPT-2 text generation model\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "# Set your prompt\n",
    "prompt = 'In the future, education will'\n",
    "\n",
    "# Generate text\n",
    "result = generator(prompt, max_length=50, temperature=0.7)\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69a033d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "North Face and Cartier hit by cyber attacks\n",
      "\n",
      "A man accused of hacking into a Canadian bank was sentenced to 18 months in jail on Tuesday for attempting to buy a gun from a bank in the U.S.\n",
      "\n",
      "Michele McIver, 26, of Calgary, was sentenced to 18 months in jail.\n",
      "\n",
      "He has pleaded not guilty to the attempted purchase of a firearm from a bank in the U.S. in May.\n",
      "\n",
      "He was ordered to pay $5,000 in restitution and $50,000 in restitution to the bank for the attempted purchase of a firearm from McIver.\n",
      "\n",
      "McIver was arrested on August 15 in San Francisco, where he had been living with his wife and two children.\n",
      "\n",
      "He was convicted of attempted purchase of a firearm and sentenced to 18 months in jail.\n",
      "\n",
      "The bank was not immediately available for comment.\n"
     ]
    }
   ],
   "source": [
    "#News Title\n",
    "prompt = 'North Face and Cartier hit by cyber attacks'\n",
    "result = generator(prompt, max_length=30, temperature=0.5)\n",
    "print(result[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76764c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are cats better than dogs?\n",
      "\n",
      "Are cat and dog lovers better off than they were when the two most popular pets were first added? If so and if we are just looking at dogs instead of cats, why are many people saying it's better to have a two year old as your pet as opposed to dog and cat lovers in addition to your dog more than other pets?\n",
      "\n",
      "Are cats better than dogs and kittens to be on different homes, lifestyles and lifestyles?\n",
      "\n",
      "More information about cats and dogs\n",
      "\n",
      "Want more info on the pros and cons of keeping your dog or cat as your pet? Then contact our helpful expert.\n",
      "\n",
      "How do you know if your dog or cat is a good dog?\n",
      "\n",
      "For the longest time, all dogs should have good temperament so you are going to want to keep your pet as happy as possible. This can be any pet, but do your research before selecting the one dog or breed you can maintain. When choosing a dog or cat you must ensure your dog should be healthy, healthy to care for, and as good, healthy as possible.\n",
      "\n",
      "How does the temperament of a dog influence any one pet?\n",
      "\n",
      "The temperament of a dog will affect the way other dogs, cats and other animals react. The best way to understand what\n"
     ]
    }
   ],
   "source": [
    "#Question\n",
    "prompt = 'Are cats better than dogs?'\n",
    "result = generator(prompt, max_length=100, temperature=1.0)\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a8660fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lights flickered and then went off, then the sirens started, it was coming, we knew it wouldn’t be the last time...we were waiting for it...\"\n",
      "\n",
      "\"You know this was not the last time we've seen you.\" Mycroft said, \"I'm sure he'll be alright, and it's only a matter of time before we're all going to have to go back. Our son will probably be dead by now. It's a great shame that something so precious might have happened to him.\"\n",
      "\n",
      "Mycroft nodded, \"The light went out and we were almost at our destination then. We're not sure what happened to him, but our best guess is that it was something from a previous accident.\"\n",
      "\n",
      "\"I dunno.\" Mycroft said, \"I think someone in his family might have tried to take him and put him there instead. Or maybe they just kept him in their room. I'm not sure.\"\n",
      "\n",
      "\"I don't think the lights went out.\" Mycroft said, \"We were not able to see him but he was clearly dead by the time we got there. He could have been dead by the time we got back.\"\n",
      "\n",
      "\"So what was that?\" Mycroft asked, \"What went wrong?\"\n",
      "\n",
      "\"Oh, they went through one hell of a lot of trouble to get him and they couldn't get his passport back\n"
     ]
    }
   ],
   "source": [
    "#Short Story Opener\n",
    "prompt = 'The lights flickered and then went off, then the sirens started, it was coming, we knew it wouldn’t be the last time...'\n",
    "result = generator(prompt, max_length=150, temperature=0.8)\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0d0d32",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "\n",
    "Now that you have experimented with text generation, write a brief report on your observations.\n",
    "\n",
    "1. What patterns did you notice in the generated text?\n",
    "2. How did changing the temperature affect the creativity and coherence of the text?\n",
    "3. What types of prompts yielded the most coherent results?\n",
    "4. What are the limitations of GPT-2 based on your experimentation?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
